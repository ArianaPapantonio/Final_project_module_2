{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creando un Jupyter solo para las migrciones a SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo Excel\n",
    "df = pd.read_excel('Book_excel.xlsx')  # Cambia 'tu_archivo.xlsx' por el nombre de tu archivo\n",
    "\n",
    "# Guardar como CSV\n",
    "df.to_csv('Book_01.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero es abrir los CSVs de cada API.\n",
    "\n",
    "# Empezamos con la extracción de Spoti, que es la que contiene todos los datos, ya que para las otras APIs\n",
    "# se han usado los artistas que arrojaba Spoti.\n",
    "\n",
    "# Abrir dataframe de spoty para luego hacer la importacion. \n",
    "dataframe_spoty_csv = pd.read_csv('../data/dataframes_combinados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_spoty_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' añadimos una columna que vaya autoincrementándose que será el id de la canción y la ponemos\n",
    "al principio del df'''\n",
    "\n",
    "dataframe_spoty_csv.insert(0, 'canción_id', range(1, len(dataframe_spoty_csv) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_spoty_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asignar un ID autoincremental a cada artista único y luego \n",
    "# reutilizar ese ID para las canciones del mismo artista.\n",
    "\n",
    "# Crear el diccionario para almacenar el ID de cada artista\n",
    "artista_id_map = {}\n",
    "current_id = 1\n",
    "\n",
    "# Función para asignar ID al artista\n",
    "def asignar_id_artista(artista):\n",
    "    global current_id\n",
    "    if artista not in artista_id_map:\n",
    "        artista_id_map[artista] = current_id\n",
    "        current_id += 1\n",
    "    return artista_id_map[artista]\n",
    "\n",
    "# Aplicar la función a cada fila y crear la columna 'artista_id'\n",
    "dataframe_spoty_csv['artista_id'] = dataframe_spoty_csv['artista'].apply(asignar_id_artista)\n",
    "\n",
    "print(dataframe_spoty_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobando que está bien viendo todas las filas del df.\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Esto vuelve a activar la opción de que no se vean todas las columnas.\n",
    "pd.reset_option('display.max_rows')\n",
    "dataframe_spoty_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HACER ESTOS PASOS ANTES DE EMPEZAR ✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a probar a importar el df a SQL.\n",
    "# Hemos creado la tabla en SQL con las columnas canción_id, nombre_cancion_album, artista_id,\n",
    "# tipo_album_cancion, año_lanzamiento, género.\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user='root'\n",
    "password='AlumnaAdalab'\n",
    "host='127.0.0.1'\n",
    "database= 'MusicStream_PR2_G2'\n",
    "connection_string = f'mysql+mysqlconnector://{user}:{password}@{host}/{database}'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spoty_sin_artista = dataframe_spoty_csv[['canción_id', 'nombre_cancion_album', 'artista_id', 'tipo_album_cancion', 'año_lanzamiento', 'género']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spoty_sin_artista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Macarena\\AppData\\Local\\Temp\\ipykernel_8220\\3052401549.py:1: UserWarning: The provided table name 'Spotify' is not found exactly as such in the database after writing the table, possibly due to case sensitivity issues. Consider using lower case table names.\n",
      "  df_spoty_sin_artista.to_sql(name='Spotify', con=engine, if_exists='append', index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spoty_sin_artista.to_sql(name='Spotify', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a hacer lo mismo para crear una tabla que contenga artistas con sus IDs, que en ppio. \n",
    "# contendrá artistas duplicados ya que viene la tabla anterior con las canciones y sus artistas.\n",
    "\n",
    "# creamos un df nuevo con las columnas que queremos y ponemos el drop_duplicates para que elimine los duplicados.\n",
    "\n",
    "df_artistas_spoty = df_spoty_sin_artista = dataframe_spoty_csv[['artista', 'artista_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artistas_spoty.to_sql(name='Artistas', con=engine, if_exists='append', index=False)\n",
    "# No deja porque artista_id es PK. Habrá que hacer una copia de la tabla de Spoti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#añadir dataframe de MB1 para ver si soluciona los artistas con distinto nombre\n",
    "dataframe_MB1_csv = pd.read_csv('../data/dataframe_MB1.csv')\n",
    "dataframe_MB1_csv.to_sql(name='musicbrainz1', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_mb_csv = pd.read_csv('../data/dataframe_MB.csv')\n",
    "dataframe_mb_csv.tosql(name='informacion_artistas', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como modificar 'None' a Null en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from time import sleep\n",
    "\n",
    "# Configuración de la conexión\n",
    "conexion = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"AlumnaAdalab\",\n",
    "    database=\"MusicStream_PR2_G2\"\n",
    ")\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# Obtener todas las tablas\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "tablas = cursor.fetchall()\n",
    "\n",
    "for (tabla,) in tablas:\n",
    "    cursor.execute(f\"SHOW COLUMNS FROM {tabla}\")\n",
    "    columnas = cursor.fetchall()\n",
    "\n",
    "    for (columna, tipo, _, _, _, _) in columnas:\n",
    "        if tipo.startswith(('char', 'varchar', 'text')):\n",
    "            try:\n",
    "                sql = f\"UPDATE {tabla} SET {columna} = NULL WHERE {columna} = 'None'\"\n",
    "                cursor.execute(sql)\n",
    "                print(f\"Actualizados valores 'None' en {tabla}.{columna}\")\n",
    "            except mysql.connector.Error as err:\n",
    "                print(f\"Error al actualizar en {tabla}.{columna}: {err}\")\n",
    "                # Esperar y reintentar\n",
    "                sleep(2)  # Espera 2 segundos antes de reintentar\n",
    "                continue\n",
    "\n",
    "# Confirmar cambios y cerrar la conexión\n",
    "conexion.commit()\n",
    "cursor.close()\n",
    "conexion.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
